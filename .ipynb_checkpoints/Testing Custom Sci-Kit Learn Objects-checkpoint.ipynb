{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Dependencies\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "#Importing Sci-kit + Stats Models Dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "\n",
    "#GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Pre-processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Scipy Integration for Sparse Matrixes\n",
    "from scipy import sparse\n",
    "\n",
    "#Plotting & Visualisation Metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Scoring & Evaluation Metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "#Pipelines\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Cleaner(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, X, salary_column= None, cols_to_drop = None, columns_to_dummify= None):\n",
    "        self.salary_column = salary_column\n",
    "        self.salary_median = X[self.salary_column].median()\n",
    "        self.cols_to_drop = cols_to_drop\n",
    "        self.columns_to_dummify= columns_to_dummify\n",
    "        self.X = X\n",
    "    \n",
    "    \n",
    "    #Creating The Salary Class \n",
    "    def salary_class(self):\n",
    "        data = ['HIGH SALARY' if item > self.salary_median else 'LOW SALARY' for item in self.X['Salaries($)']]\n",
    "        return data\n",
    "    \n",
    "\n",
    "    #Creating The States + Locations Features\n",
    "    def state_and_locations(self):\n",
    "        states = [str(item).split()[-1] for item in self.X['Locations']]\n",
    "        locations = [(\" \".join(str(item).split()[:-1])).replace(',','') for item in cleaned_df['Locations']]   \n",
    "        return states, locations\n",
    "    \n",
    "    \n",
    "    def dropping_cols(self):\n",
    "        return self.X.drop(columns= self.cols_to_drop, inplace=True)\n",
    "    \n",
    "    \n",
    "    def make_dummy_cols(self):\n",
    "        for column in self.columns_to_dummify:\n",
    "            try:\n",
    "                categories = np.sort(self.X[column].unique())\n",
    "                for category in categories[1:]:\n",
    "                    self.X[column+'_'+str(category)] = self.X[column].map(\n",
    "                        lambda x: 1 if x == category else 0)\n",
    "                self.X = self.X.drop(column, axis=1)\n",
    "            except:\n",
    "                pass\n",
    "        return self.X\n",
    "    \n",
    "    \n",
    "    def transform(self, *args):\n",
    "        #Cleaning & Adding Features.\n",
    "        self.X['Salary_Class'] = self.salary_class()\n",
    "        self.X['State'] = self.state_and_locations()[0]\n",
    "        self.X['Locations'] = self.state_and_locations()[1]\n",
    "        \n",
    "        #Dropping Columns.\n",
    "        self.dropping_cols()\n",
    "        \n",
    "        #Dropping NA Values.\n",
    "        self.X.dropna(how='any', inplace=True)\n",
    "        \n",
    "        #Dummfying The Data\n",
    "        self.make_dummy_cols()\n",
    "        return self.X\n",
    "     \n",
    "        \n",
    "    def fit(self, *args):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TFID_Vectorizer Helper Class For The Pipeline!\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class TFID_Vectorizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, X, cols_to_vectorize = None):\n",
    "        self.cols_to_vectorize = cols_to_vectorize   \n",
    "        self.tvec = TfidfVectorizer(stop_words='english')\n",
    "        self.original_sparse = None\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y=None, *args):\n",
    "        self.tvec = self.tvec.fit(X[self.cols_to_vectorize])\n",
    "        X = X[X.columns.difference(['Titles'])]\n",
    "        self.original_sparse = sparse.csr_matrix(X.values)\n",
    "        return self.tvec\n",
    " \n",
    "\n",
    "    def transform(self, X, y=None, *args):\n",
    "        if isinstance(X, pd.DataFrame):            \n",
    "            Additional_Data = X[X.columns.difference(['Titles'])]\n",
    "            Sparse_Original_Data = sparse.csr_matrix(Additional_Data.values)\n",
    "            Y = self.tvec.transform(X[self.cols_to_vectorize])\n",
    "            X = sparse.hstack([Y, Sparse_Original_Data])\n",
    "            \n",
    "        else:    \n",
    "            print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.read_csv(\"exported_dataframe.csv\")\n",
    "Clean_mod = Cleaner(salary_column='Salaries($)', X = cleaned_df, cols_to_drop=['Companies', 'Salaries($)']\n",
    "                   , columns_to_dummify = ['State', 'Locations'] )\n",
    "X = Clean_mod.transform()\n",
    "y = X.pop('Salary_Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing A Train Test Split.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = TFID_Vectorizer(X, cols_to_vectorize='Titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<87x304 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0467bad5b08d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 86)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<87x304 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test Data Shape \n",
    "\n",
    "- Sparse Original Shape: 58 rows ,86 columns\n",
    "- Job Titles Original Shape: 58 rows, 304 columns\n",
    "- New Sparse Matrix Shape: 58 rows, 390 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 86)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<87x304 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-40-3879ebf30003>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-40-3879ebf30003>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    ('LogisticRegression', LogisticRegressionCV())] verbose=False)\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Creating The Pipeline\n",
    "\n",
    "pipe = Pipeline(memory=None,\n",
    "         steps=[('TFID_Vectorizing', testing,\n",
    "                ('LogisticRegression', LogisticRegressionCV())] verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-eab3d6719c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sparse.csr_matrix(X_train[X_train.columns.difference(['Titles'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230, 86)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 86)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sparse.hstack([a, a])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
